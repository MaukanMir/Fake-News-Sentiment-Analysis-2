{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fake News Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Models \n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Data Processing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer, f1_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from transformers import pipeline\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "import torch\n",
    "\n",
    "import nltk\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "\n",
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_class_imbalance(df:pd.DataFrame, target:pd.Series, col:str):\n",
    "  counter = Counter(target)\n",
    "  for k,v in counter.items():\n",
    "    per = v/len(target) * 100\n",
    "    print(\"Class=%s, Count=%d, Percentage=%.3f%%\" % (k,v, per))\n",
    "  df[col].value_counts().plot.bar()\n",
    "  \n",
    "def remove_stop_words(review:str):\n",
    "    word_tokens = \" \".join(word_tokenize(review))\n",
    "    filtered_word_tokens = re.sub(r'[^a-zA-Z\\s]', '', word_tokens).split(\" \")\n",
    "    filtered_sentence = [w.lower().strip() for w in filtered_word_tokens if not w.lower() in ENGLISH_STOP_WORDS]\n",
    "    return ' '.join(filtered_sentence).strip()\n",
    "def evaluate_model(X, y, model):\n",
    "  cv = RepeatedStratifiedKFold(n_splits=5, n_repeats=3, random_state=1)\n",
    "  \n",
    "  metric = make_scorer(f1_score)\n",
    "  scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n",
    "  return scores\n",
    "\n",
    "def testing_selected_models(names:list, models:list, X:pd.DataFrame, y:pd.Series):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    model_performance = []\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        # Evaluate the model\n",
    "        scores = evaluate_model(X, y, model)\n",
    "        # summarize and store\n",
    "        model_performance.append({\n",
    "            \"Model\": names[i],\n",
    "            \"Mean\": np.mean(scores),\n",
    "            \"STD\":np.std(scores)\n",
    "        })\n",
    "    performance_df = pd.DataFrame(model_performance)\n",
    "    return performance_df.sort_values(by=\"Mean\", ascending=False)\n",
    "def get_selected_models(names):\n",
    "  \"\"\"\n",
    "  Returns selected models for ML processing\n",
    "\n",
    "  Args:\n",
    "      names (_type_):List\n",
    "\n",
    "  Returns:\n",
    "      List of models\n",
    "  \"\"\"\n",
    "  models = {\n",
    "    \"LDA\": LinearDiscriminantAnalysis(),\n",
    "    \"GPC\": GaussianProcessClassifier(),\n",
    "    \"GNB\": GaussianNB(),\n",
    "    \"SVC\": SVC(),\n",
    "    \"LR\":LogisticRegression(max_iter=1000),\n",
    "    \"KNN\": KNeighborsClassifier(),\n",
    "    \"DTC\": DecisionTreeClassifier(),\n",
    "    \"GBC\":GradientBoostingClassifier(),\n",
    "    \"RFC\":RandomForestClassifier(),\n",
    "    \"XGB\": XGBClassifier(),\n",
    "    \"MN\": MultinomialNB()\n",
    "  }\n",
    "  \n",
    "  return [models[model] for model in names]\n",
    "\n",
    "def testing_selected_models(names:list, models:list, X:pd.DataFrame, y:pd.Series):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    model_performance = []\n",
    "    for i in range(len(models)):\n",
    "        model = models[i]\n",
    "        scores = evaluate_model(X, y, model)\n",
    "        model_performance.append({\n",
    "            \"Model\": names[i],\n",
    "            \"Mean\": np.mean(scores),\n",
    "            \"STD\":np.std(scores)\n",
    "        })\n",
    "    performance_df = pd.DataFrame(model_performance)\n",
    "    return performance_df.sort_values(by=\"Mean\", ascending=False)\n",
    "def grid_search_selected_models(param_grid:dict,names:list, models:list, X:pd.DataFrame, y:pd.Series, metric):\n",
    "    \"\"\"\n",
    "    Runs multiple subsets on folds of data\n",
    "\n",
    "    Args:\n",
    "        names (list): _description_\n",
    "        models (list): _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "\n",
    "    model_performance = []\n",
    "\n",
    "    for i in range(len(models)):\n",
    "        model, name = models[i], names[i]\n",
    "            \n",
    "        grid_search = GridSearchCV(model, param_grid[name], cv=2, scoring=metric, n_jobs=-1)\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_model = grid_search.best_estimator_\n",
    "            \n",
    "        # Predict on the test set\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        accuracy = accuracy_score(y_test, y_pred)\n",
    "            \n",
    "        print(f'Best score for {name}: {grid_search.best_score_:.3f}')\n",
    "        print(\"Best parameters:\", grid_search.best_params_)\n",
    "        \n",
    "        print(f'Test accuracy for {name}: {accuracy:.3f}')\n",
    "        print(\"---------------------------------------------------------------\")\n",
    "        \n",
    "        conf_mat = confusion_matrix(y_test, y_pred)\n",
    "        # Plot the confusion matrix\n",
    "        plt.figure(figsize=(8,6))\n",
    "        sns.heatmap(conf_mat, annot=True, fmt='d', cmap='Blues')\n",
    "        plt.xlabel('Predicted Labels')\n",
    "        plt.ylabel('True Labels')\n",
    "        plt.title(f'Confusion Matrix for {names[i]}')\n",
    "        plt.show()\n",
    "            \n",
    "        model_performance.append({\n",
    "                \"Model\": name,\n",
    "                \"Best CV Score\": grid_search.best_score_,\n",
    "                \"Test Accuracy\": accuracy,\n",
    "                \"Best Parameters\": grid_search.best_params_\n",
    "        })\n",
    "\n",
    "\n",
    "    model_performance_df = pd.DataFrame(model_performance)\n",
    "    print(model_performance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df = pd.read_csv(\"/Users/maukanmir/Downloads/archive/True.csv\",nrows=5000)\n",
    "fake_df = pd.read_csv(\"/Users/maukanmir/Downloads/archive/Fake.csv\",nrows=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Target Column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_df['target'] = 1\n",
    "true_df['target'] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Drop Dupes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "true_df.drop_duplicates(inplace=True)\n",
    "fake_df.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([true_df,fake_df]).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(\"index\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Class Imbalance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class=0, Count=4965, Percentage=49.824%\n",
      "Class=1, Count=5000, Percentage=50.176%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "check_class_imbalance(df, df['target'], 'target')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"date\"] = pd.to_datetime(df[\"date\"],errors='coerce', utc=True)\n",
    "\n",
    "df['year'] = df[\"date\"].dt.year\n",
    "df['month'] = df[\"date\"].dt.month\n",
    "df['day'] = df[\"date\"].dt.day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['subject', 'date'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       washington  reuters   head conservative republ...\n",
       "1       washington  reuters   transgender people allow...\n",
       "2       washington  reuters   special counsel investig...\n",
       "3       washington  reuters   trump campaign adviser g...\n",
       "4       seattlewashington  reuters   president donald ...\n",
       "                              ...                        \n",
       "9960    s secret republicans salivating   hillary clin...\n",
       "9961    republicans lose huge source funding justice d...\n",
       "9962    pawn working donald trump claimed women respec...\n",
       "9963    fox news desperate sabotage hillary clinton s ...\n",
       "9964    donald trump s campaign continues sink deeper ...\n",
       "Name: text, Length: 9965, dtype: object"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].apply(lambda text: remove_stop_words(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       budget fight looms  republicans flip fiscal sc...\n",
       "1       military accept transgender recruits monday  p...\n",
       "2           senior republican senator  let mr mueller job\n",
       "3       fbi russia probe helped australian diplomat ti...\n",
       "4       trump wants postal service charge  amazon ship...\n",
       "                              ...                        \n",
       "9960      fbi warns republicans  leak clinton email files\n",
       "9961    justice department announces longer use privat...\n",
       "9962    watch  se  cupp destroys trump adviser  s  fan...\n",
       "9963    watch  fox hosts claim hillary brain damage we...\n",
       "9964    cnn panelist laughs corey lewandowski  s face ...\n",
       "Name: title, Length: 9965, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['title'].apply(lambda title: remove_stop_words(title))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizer, DistilBertModel\n",
    "\n",
    "tokenizer = DistilBertTokenizer.from_pretrained('distilbert-base-cased')\n",
    "model = DistilBertModel.from_pretrained('distilbert-base-cased')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_embeddings(text):\n",
    "    inputs = tokenizer(text, return_tensors=\"pt\", padding=True, truncation=True, max_length=512)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    last_hidden_states = outputs.last_hidden_state\n",
    "    \n",
    "    mean_embeddings = last_hidden_states.mean(dim=1)\n",
    "    return mean_embeddings.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['title_embeddings'] = new_df['title'].apply(lambda x: get_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df['text_embeddings'] = new_df['text'].apply(lambda x: get_embeddings(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Normalize/Scale other features\n",
    "scaler = StandardScaler()\n",
    "new_df['day_scaled'] = scaler.fit_transform(df[['day']])\n",
    "new_df['month_scaled'] = scaler.fit_transform(df[['month']])\n",
    "new_df['year_scaled'] = scaler.fit_transform(df[['year']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_embeddings_flat = np.array(new_df['title_embeddings'].tolist()).reshape(new_df.shape[0], -1)\n",
    "text_embeddings_flat = np.array(new_df['text_embeddings'].tolist()).reshape(new_df.shape[0], -1)\n",
    "\n",
    "features = np.concatenate([title_embeddings_flat, text_embeddings_flat, new_df[['day_scaled', 'month_scaled', 'year_scaled']].values], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Separate Feature Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = features, new_df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 0.502 (0.010)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "\n",
    "model = DummyClassifier(strategy='uniform') \n",
    "\n",
    "scores = evaluate_model(features, y, model)\n",
    "print('Mean: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Model Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RFC</td>\n",
       "      <td>0.998966</td>\n",
       "      <td>0.000785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>XGB</td>\n",
       "      <td>0.998333</td>\n",
       "      <td>0.000788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>DTC</td>\n",
       "      <td>0.990146</td>\n",
       "      <td>0.002162</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model      Mean       STD\n",
       "1   RFC  0.998966  0.000785\n",
       "0   XGB  0.998333  0.000788\n",
       "2   DTC  0.990146  0.002162"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['XGB', \"RFC\", \"DTC\"]\n",
    "models = get_selected_models(names)\n",
    "testing_selected_models(names, models, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LR</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model  Mean  STD\n",
       "0    LR   1.0  0.0\n",
       "1   SVC   1.0  0.0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['LR', \"SVC\"]\n",
    "models = get_selected_models(names)\n",
    "testing_selected_models(names, models, X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Mean</th>\n",
       "      <th>STD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LDA</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>0.997739</td>\n",
       "      <td>0.0007</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Model      Mean     STD\n",
       "1   LDA  1.000000  0.0000\n",
       "0   KNN  0.997739  0.0007"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = ['KNN', \"LDA\"]\n",
    "models = get_selected_models(names)\n",
    "testing_selected_models(names, models, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maukanmir/miniforge3/envs/machine-learning-env/lib/python3.9/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py:114: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  super().__init__(name, **kwargs)\n",
      "/var/folders/bb/2qsf8cm95jg05zrms2_8m2qr0000gn/T/ipykernel_77804/2870477699.py:10: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(\n",
      "2024-04-30 17:15:07.579702: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "/var/folders/bb/2qsf8cm95jg05zrms2_8m2qr0000gn/T/ipykernel_77804/2870477699.py:17: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(\n",
      "/var/folders/bb/2qsf8cm95jg05zrms2_8m2qr0000gn/T/ipykernel_77804/2870477699.py:25: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead. See https://www.adriangb.com/scikeras/stable/migration.html for help migrating.\n",
      "  model = KerasClassifier(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Optimizer</th>\n",
       "      <th>Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>RmsProp</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SGD:0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dropout</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SGD:0.001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SGD:0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>L1</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SGD:0.001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SGD:0.01</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>L2</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>SGD:0.001</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>L2</td>\n",
       "      <td>0.999666</td>\n",
       "      <td>RmsProp</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>L1</td>\n",
       "      <td>0.991304</td>\n",
       "      <td>RmsProp</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L1</td>\n",
       "      <td>0.489632</td>\n",
       "      <td>Adam</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Model  Accuracy  Optimizer   Value\n",
       "0   Dropout  1.000000       Adam  0.1000\n",
       "1   Dropout  1.000000    RmsProp  0.0100\n",
       "2   Dropout  1.000000   SGD:0.01  0.0010\n",
       "3   Dropout  1.000000  SGD:0.001  0.0001\n",
       "6        L1  1.000000   SGD:0.01  0.0010\n",
       "7        L1  1.000000  SGD:0.001  0.0001\n",
       "8        L2  1.000000       Adam  0.1000\n",
       "10       L2  1.000000   SGD:0.01  0.0010\n",
       "11       L2  1.000000  SGD:0.001  0.0001\n",
       "9        L2  0.999666    RmsProp  0.0100\n",
       "5        L1  0.991304    RmsProp  0.0100\n",
       "4        L1  0.489632       Adam  0.1000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "from keras.regularizers import l2, l1\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "\n",
    "def create_keras_classifier(function, optimizer, idx, param):\n",
    "    if idx == 0:\n",
    "        \n",
    "        model = KerasClassifier(\n",
    "            build_fn=lambda: function(input_dim=X_train.shape[1], optimizer=optimizer)\n",
    "            , epochs=100, \n",
    "            batch_size=64, \n",
    "            verbose=0\n",
    "            )\n",
    "    elif idx ==1:\n",
    "        model = KerasClassifier(\n",
    "            build_fn=lambda: function(input_dim=X_train.shape[1], optimizer=optimizer, param=param)\n",
    "            , epochs=100, \n",
    "            batch_size=64, \n",
    "            verbose=0\n",
    "            )\n",
    "        \n",
    "    else:\n",
    "        model = KerasClassifier(\n",
    "            build_fn=lambda: function(input_dim=X_train.shape[1], optimizer=optimizer, param=param)\n",
    "            , epochs=100, \n",
    "            batch_size=64, \n",
    "            verbose=0\n",
    "            )\n",
    "    return model\n",
    "\n",
    "def create_model_dropout(input_dim, optimizer='adam'):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "def create_model_regularizerl2(input_dim, optimizer=\"adam\",param= 0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu', kernel_regularizer=l2(param) ))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "def create_model_regularizerL1(input_dim, optimizer=\"adam\",param= 0.001):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_dim=input_dim, activation='relu', activity_regularizer=l1(param) ))\n",
    "    model.add(Dense(32, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "functions = [\n",
    "  create_model_dropout,\n",
    "  create_model_regularizerL1,\n",
    "  create_model_regularizerl2\n",
    "]\n",
    "\n",
    "optimizers = [\n",
    "    Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07),\n",
    "    RMSprop(learning_rate=0.001, rho=0.9, momentum=0.0, epsilon=1e-07),\n",
    "    SGD(lr=0.01, momentum=0.9), \n",
    "    SGD(lr=0.001, momentum=0.9),\n",
    "    ]\n",
    "optimizer_names = ['Adam', \"RmsProp\", \"SGD:0.01\", \"SGD:0.001\"]\n",
    "function_names = [\"Dropout\", \"L1\", \"L2\"]\n",
    "values = [1e-1, 1e-2, 1e-3, 1e-4]\n",
    "model_performance = []\n",
    "for index, function in enumerate(functions):\n",
    "    name = function_names[index]\n",
    "    for idx, optimizer in enumerate(optimizers):\n",
    "        optimizer_name = optimizer_names[idx]\n",
    "        value = values[idx]\n",
    "        model = create_keras_classifier(function, optimizer, index, value)\n",
    "        \n",
    "        model.fit(X_train, y_train)\n",
    "        accuracy = model.score(X_test, y_test)\n",
    "        model_performance.append({\n",
    "            \"Model\": name,\n",
    "            \"Accuracy\": accuracy,\n",
    "            \"Optimizer\": optimizer_name,\n",
    "            \"Value\": value\n",
    "        })\n",
    "model_df = pd.DataFrame(model_performance)\n",
    "end_result = model_df.sort_values(by=\"Accuracy\", ascending=False)\n",
    "end_result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
